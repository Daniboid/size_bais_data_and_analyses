---
title: "LDT Size Bias Analyses"
author: "Dani Larranaga"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!require(psych))     {install.packages("psych");     require(psych)}
if(!require(irr))       {install.packages("irr");       require(irr)}
if(!require(tidyr))     {install.packages("tidyr");     require(tidyr)}
if(!require(lme4))      {install.packages("lme4");      require(lme4)}
if(!require(lmerTest))  {install.packages("lmerTest");  require(lmerTest)}
if(!require(bmlm))      {install.packages("bmlm");      require(bmlm)}
if(!require(rstatix))   {install.packages("rstatix");   require(rstatix)}

# Load Data
load("LDT_OpenData.Rdata")

## Bayesian Mediation Analyses take *FOREVER* to run, so loading this data is much faster.
load("Accuracy_Gender_BMLM.RData")
load("Accuracy_Familiarity_BMLM.RData")
load("RT_Gender_BMLM.RData")
load("RT_Familiarity_BMLM.RData")
```


# Study 1: Direct Replication

## Participant Level:

### RT
```{r}
t.PL.RT = t.test(LDT.participantLevel$RT_Small, LDT.participantLevel$RT_Large, paired = T)
t.PL.RT

d = unname(t2d(t.PL.RT$statistic, n=108))
d
```

### Error Rate
```{r}
t.PL.ER = t.test(LDT.participantLevel$Small.Accuracy, LDT.participantLevel$Large.Accuracy, paired = T)
t.PL.ER

d = unname(t2d(t.PL.ER$statistic, n=108))
d
```

### Inverse Efficiency Score (IES)
```{r}
t.PL.IES = t.test(LDT.participantLevel$Small_IES, LDT.participantLevel$Large_IES, paired = T)
t.PL.IES

d = unname(t2d(t.PL.IES$statistic, n=108))
d
```


## Word-Pair Level:

### RT
```{r}
t.WP.RT = t.test(LDT.wordPairLevel$RT_Small, LDT.wordPairLevel$RT_Large, paired = T)
t.WP.RT

d = unname(t2d(t.WP.RT$statistic, n=108))
d
```

### Error Rate
```{r}
t.WP.ER = t.test(LDT.wordPairLevel$WP.Acc.Small, LDT.wordPairLevel$WP.Acc.Large, paired = T)
t.WP.ER

d = unname(t2d(t.WP.ER$statistic, n=108))
d
```

### IES
```{r}
t.WP.IES = t.test(LDT.wordPairLevel$Small_IES, LDT.wordPairLevel$Large_IES, paired = T)
t.WP.IES

d = unname(t2d(t.WP.IES$statistic, n=108))
d
```




# Study 2: Norming Differences

```{r}
df.Norm.WP = pivot_wider(WR.scaledDimsOfInterest[,2:10],
                         id_cols = c("WordPair"),
                         names_from = c("size"), 
                         values_from = c(3:9))
```

## Intraclass Correlations

USING THE SCALED VARIABLES!!! (because GN has them on different scales)

```{r results = 'asis'}

m = "two"
t = "agreement"
s = "single"


size_icc = icc(cbind(WR.scaledDimsOfInterest$Size,
                     WR.scaledDimsOfInterest$SIZE.Glasgow_Norms),
               model = m, type = t, unit = s)
val_icc  = icc(cbind(WR.scaledDimsOfInterest$Valence,
                    WR.scaledDimsOfInterest$VAL.Glasgow_Norms),
               model = m, type = t, unit = s)
gend_icc = icc(cbind(WR.scaledDimsOfInterest$Gender,
                     WR.scaledDimsOfInterest$GEND.Glasgow_Norms),
               model = m, type = t, unit = s)
img_icc  = icc(cbind(WR.scaledDimsOfInterest$Imagability,
                     WR.scaledDimsOfInterest$IMAG.Glasgow_Norms),
               model = m, type = t, unit = s)
conc_icc = icc(cbind(WR.scaledDimsOfInterest$Concreteness,
                     WR.scaledDimsOfInterest$CNC.Glasgow_Norms),
               model = m, type = t, unit = s)
arou_icc = icc(cbind(WR.scaledDimsOfInterest$Arousal,
                     WR.scaledDimsOfInterest$AROU.Glasgow_Norms),
               model = m, type = t, unit = s)
fam_icc  = icc(cbind(WR.scaledDimsOfInterest$Familiarity,
                     WR.scaledDimsOfInterest$FAM.Glasgow_Norms),
               model = m, type = t, unit = s)

ests = c(size_icc$value, val_icc$value, gend_icc$value, img_icc$value,
         conc_icc$value, arou_icc$value, fam_icc$value)
lbs = c(size_icc$lbound, val_icc$lbound, gend_icc$lbound, img_icc$lbound,
        conc_icc$lbound, arou_icc$lbound, fam_icc$lbound)
ubs = c(size_icc$ubound, val_icc$ubound, gend_icc$ubound, img_icc$ubound,
        conc_icc$ubound, arou_icc$ubound, fam_icc$ubound)
sigs = c(size_icc$p.value, val_icc$p.value, gend_icc$p.value, img_icc$p.value,
         conc_icc$p.value, arou_icc$p.value, fam_icc$p.value)

forkable = data.frame(ests, lbs, ubs, sigs)
rownames(forkable) = c("size", "valence", "gender", "imageability",
                       "concreteness", "aorusal", "familiarity")


print(knitr::kable(forkable[order(forkable$ests, decreasing = T),], bookend = T, digits = 3))



```


## *t*s between US and UK

```{r demnsionalTs, results='asis'}
forkable = data.frame(Dimension = c(""), 
                      t.value = c(0),
                      p.value = c(0))
forkable = forkable[-1,]

for(d in 1:7){
  d.PU = d*2+2
  d.GN = d*2+3
  
  v = names(WR.scaledDimsOfInterest)[d.PU]
  
  tmp.t = t.test(WR.scaledDimsOfInterest[,d.PU], WR.scaledDimsOfInterest[,d.GN], paired = T)
  
  forkable[d,] = cbind(v, round(tmp.t$statistic,3), round(tmp.t$p.value,3))
}

print(knitr::kable(forkable[order(forkable$t.value),], bookend = T, row.names = F, digits = 3))
```


## *t*s between word groups

```{r wordGroupTs, results='asis'}
forkable = data.frame(Dimension = c(""), 
                      `S_Mean_PU` = c(0),
                      `L_Mean_PU` = c(0),
                      `S_95CI_PU` = c(0),
                      `L_95CI_PU` = c(0),
                      t.value.PU = c(0),
                      p.value.PU = c(0), 
                      `S Mean GN` = c(0),
                      `L Mean GN` = c(0),
                      t.value.GN = c(0),
                      p.value.GN = c(0))
forkable = forkable[-1,]

for(d in 1:8){
  d.s.PU = d*4-2
  d.l.PU = d*4-1
  d.s.GN = d*4
  d.l.GN = d*4+1
  
  v = gsub("_Small", "", names(WR.wordPairs)[d.s.PU])
  
  sm.PU      = mean(WR.wordPairs[,d.s.PU], na.rm = T)
  lm.PU      = mean(WR.wordPairs[,d.l.PU], na.rm = T)
  sm.PU.95CI = 1.96*(sd(WR.wordPairs[,d.s.PU], na.rm = T) / sqrt(length(WR.wordPairs[,d.s.PU])))
  lm.PU.95CI = 1.96*(sd(WR.wordPairs[,d.l.PU], na.rm = T) / sqrt(length(WR.wordPairs[,d.l.PU])))
  
  sm.GN = mean(WR.wordPairs[,d.s.GN], na.rm = T)
  lm.GN = mean(WR.wordPairs[,d.l.GN], na.rm = T)
  
  tmp.t.PU = t.test(WR.wordPairs[, d.l.PU], WR.wordPairs[, d.s.PU], paired = T)
  tmp.t.GN = t.test(WR.wordPairs[, d.l.GN], WR.wordPairs[, d.s.GN], paired = T)
  
  forkable[d,] = cbind(v, round(sm.PU,3), round(lm.PU,3), round(sm.PU.95CI,4), round(lm.PU.95CI,4), round(tmp.t.PU$statistic,3), round(tmp.t.PU$p.value,3), 
                          round(sm.GN,3), round(lm.GN,3), round(tmp.t.GN$statistic,3), round(tmp.t.GN$p.value,3))
}

print(knitr::kable(forkable, bookend = T, row.names = F, digits = 3))

forGraph = pivot_longer(forkable[,1:5],2:5, names_to = c("size","scale", "locus"), names_sep = "_")
forGraph = data.frame(pivot_wider(forGraph,id_cols = c("size"), names_from = c(1,3)))

forGraph$size = factor(forGraph$size, levels = c("S", "L"))
for(co in 2:15){
  forGraph[,co] = as.numeric(forGraph[,co])
}
```

## ANOVAs
```{r results='hide', warning=FALSE}
# Compare GN to PU on *scaled* dims o interest
forkable = data.frame(Dimension = c(""),
                      `S_Mean_PU` = c(0),
                      `L_Mean_PU` = c(0),
                      `S Mean GN` = c(0),
                      `L Mean GN` = c(0),
                      effect = c(""),
                      F.val = c(0),
                      df_a = c(0),
                      df_e = c(0),
                      eta_sq = c(0),
                      p.val = c(0))
forkable = forkable[-1,]

for(d in names(WR.scaledInteract)[5:11]){

  sm.PU = mean(dplyr::pull(WR.scaledInteract[WR.scaledInteract$size == "Small" & WR.scaledInteract$Location == "PU",d]),
                     na.rm = T)
  lm.PU = mean(dplyr::pull(WR.scaledInteract[WR.scaledInteract$size == "Large" & 
                                         WR.scaledInteract$Location == "PU", d]),
                     na.rm = T)
  sm.GN = mean(dplyr::pull(WR.scaledInteract[WR.scaledInteract$size == "Small" & 
                                         WR.scaledInteract$Location == "GN", d]),
                     na.rm = T)
  lm.GN = mean(dplyr::pull(WR.scaledInteract[WR.scaledInteract$size == "Large" & 
                                         WR.scaledInteract$Location == "GN", d]),
                     na.rm = T)
  forkable = rbind(forkable,
                   data.frame(Dimension = d, 
                              `S_Mean_PU` = sm.PU, 
                              `L_Mean_PU` = lm.PU, 
                              `S Mean GN` = sm.GN, 
                              `L Mean GN` = lm.GN, 
                              effect = "",
                              F.val = NaN,
                              df_a = NaN,
                              df_e = NaN,
                              eta_sq = NaN,
                              p.val = NaN)
                   )
  
  tmp.ANOVA = WR.scaledInteract %>% 
                anova_test(dv = d,
                           wid = WordPair,
                           within = size,
                           between = Location) 
  cat(paste("\n\n", d, "\n\n"))
  print(tmp.ANOVA)
  for (r in 1:nrow(tmp.ANOVA)) {
    forkable = rbind(forkable,
                     data.frame(Dimension = NA, 
                              `S_Mean_PU` = NaN, 
                              `L_Mean_PU` = NaN, 
                              `S Mean GN` = NaN, 
                              `L Mean GN` = NaN, 
                              effect = tmp.ANOVA$Effect[r],
                              F.val = round(tmp.ANOVA$F[r], 3),
                              df_a = round(tmp.ANOVA$DFn[r],3),
                              df_e = round(tmp.ANOVA$DFd[r], 3),
                              eta_sq = round(tmp.ANOVA$ges[r],3),
                              p.val = round(tmp.ANOVA$p[r], 3))
    )
  }
}
```
```{r results='asis'}
options(knitr.kable.NA = "")
print(knitr::kable(forkable, bookend = T, row.names = F, digits = 3))
```

# Study 3: Multi-level Mediation

## RT
```{r echo=T}
LDT.finalData$Familiarity_c = LDT.finalData$Familiarity - mean(LDT.finalData$Familiarity)
LDT.finalData$Gender   = 7 - LDT.finalData$Femininity
LDT.finalData$Gender_c = LDT.finalData$Gender - mean(LDT.finalData$Gender)
LDT.finalData$Size_c   = LDT.finalData$Size - mean(LDT.finalData$Size)

WR.data$Familiarity_c = WR.data$Familiarity - mean(WR.data$Familiarity)
WR.data$Size_c = WR.data$Size - mean(WR.data$Size)
WR.data$Gender_c = WR.data$Gender - mean(WR.data$Gender)

mlm_1 = lmer(RT ~ Size_c *  + (1 | SubID), LDT.finalData)
summary(mlm_1)

```


### Familiarity and Gender Plots
```{r echo=T}
# Familiarity
mlm_3 = lmer(RT ~ Familiarity_c + Size_c + (1 | SubID), LDT.finalData)
summary(mlm_3)

leg_1 = lmer(Familiarity_c ~ Size_c + (1|SubID), LDT.finalData[LDT.finalData$RT,])
summary(leg_1)


# rt_fam_bmlm = mlm(LDT.finalData[!is.na(LDT.finalData$RT),],
#                   id = "SubID",
#                   x = "Size_c",
#                   m = "Familiarity_c",
#                   y = "RT")
mlm_summary(rt_fam_bmlm)

# Gender
mlm_2 = lmer(RT ~ Gender_c + Size_c + (1 | SubID), LDT.finalData)
summary(mlm_2)

leg_2 = lm(Gender ~ Size, WR.data)
summary(leg_2)

# rt_gend_bmlm = mlm(LDT.finalData[!is.na(LDT.finalData$RT),],
#                   id = "SubID",
#                   x = "Size_c",
#                   m = "Gender_c",
#                   y = "RT")
mlm_summary(rt_gend_bmlm)

# Double
mlm_4 = lmer(RT ~ Familiarity_c + Gender_c + Size_c + (1 | SubID), LDT.finalData)
summary(mlm_4)

# Fit
anova(mlm_1, mlm_2, mlm_3, mlm_4)

```


## ACC
```{r echo=T}
mlm_1 = glmer(ACCURACY ~ Size + (1 | SubID), LDT.finalData, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e6)))
summary(mlm_1)
exp(fixef(mlm_1))

```


### Familiarity and Gender Plots
```{r echo=T}



# Familiarity
mlm_3 = glmer(ACCURACY ~ Familiarity_c + Size_c + (1 | SubID), LDT.finalData, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
summary(mlm_3)
exp(fixef(mlm_3))

leg_1 = lm(Familiarity ~ Size, WR.data)
summary(leg_1)

# acc_fam_bmlm = mlm(LDT.finalData[!is.na(LDT.finalData$RT),],
#                   id = "SubID",
#                   x = "Size_c",
#                   m = "Familiarity_c",
#                   y = "ACCURACY",
#                   binary_y = T)
mlm_summary(acc_fam_bmlm)


# Gender
mlm_2 = glmer(ACCURACY ~ Gender_c + Size_c + (1 | SubID), LDT.finalData, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
summary(mlm_2)
exp(fixef(mlm_2))

leg_2 = lm(Gender ~ Size, WR.data)
summary(leg_2)

# acc_gend_bmlm = mlm(LDT.finalData[!is.na(LDT.finalData$RT),],
#                   id = "SubID",
#                   x = "Size_c",
#                   m = "Gender_c",
#                   y = "ACCURACY",
#                   binary_y = T)
mlm_summary(acc_gend_bmlm)
# save(list = c("rt_gend_bmlm", "rt_fam_bmlm", "acc_fam_bmlm", "acc_gend_bmlm"), 
#      file = "All_Bayesian_Mediations.RData")


## Double
mlm_4 = glmer(ACCURACY ~ Familiarity_c + Gender_c + Size_c + (1 | SubID), LDT.finalData, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
summary(mlm_4)
exp(fixef(mlm_4))


# Best Fit
anova(mlm_1, mlm_2, mlm_3, mlm_4)

```

